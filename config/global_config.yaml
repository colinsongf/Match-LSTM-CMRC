data:
  dataset:
    train_path: data/cmrc/cmrc2018_train.json
    dev_path: data/cmrc/cmrc2018_dev.json
  dataset_h5: data/cmrc_embeddings.h5

  embedding_path: /Users/han/embeddings/sgns.merge.word.bz2
  embedding_h5: /Users/han/embeddings/sgns.merge.word.h5

  add_features_h5: data/add_features.h5

  model_path: data/model-weight.pt
  rerank_model_path: data/rerank-model-weight.pt
  checkpoint_path: data/checkpoint

global:
  random_seed: 123
  num_data_workers: 5   # for data loader
  enable_rerank: False
  rank_k: 3

preprocess:
  word_embedding_size: 300
  ignore_max_len: 600 # in train data, context token len > ignore_max_len will be dropped
  use_char: False # not used in chinese dataset
  use_pos: True
  use_ent: False  # not used in chinese dataset
  use_em: True
  use_em_lemma: False # not used in chinese dataset

train:
  batch_size: 32
  valid_batch_size: 32
  epoch: 30
  enable_cuda: True

  optimizer: 'adamax'  # adam, sgd, adamax, adadelta(default is adamax)
  learning_rate: 0.002  # only for sgd
  clip_grad_norm: 5

test:
  batch_size: 32
  enable_cuda: True